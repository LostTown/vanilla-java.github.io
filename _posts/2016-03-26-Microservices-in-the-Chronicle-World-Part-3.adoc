= Microservices in the Chronicle World - Part 3
:hp-tags: JMH, Chronicle-Queue, Microservices

One of the problem with using micro-services is performance.  Both latencies are higher due to the cost of serialization, messaging and deserialization, and this reduces throughput.  In particular poor throughput is a problem because the reason we are designing a scalable system is to increase throughput.

=== Benchmarking with JMH

http://openjdk.java.net/projects/code-tools/jmh/[JMH] which might stand for Java Micro-benchamrk Harness is an exelent tool for measureing the throughput and sample latencies end to end.  We can look at an example of what it good for with regard to our example.  We added our own micro-benchamrk harness for asynchronous tasks run across multiple threads where you want to time individual portion (which will be covered in the next Part). For now we will look at latencies end-to-end.

=== Our JMH services latency test

As mentioned pervious, we can only measure timings not portions of the benchmark. For this reason we cannot time a service standalone but must include the producer. We must also look at the timing of one thread.

.Our JMH benchmark
[source, java]
----
@Setup
public void setup() {
    String target = OS.TMP;
    upQueuePath = new File(target, "ComponentsBenchmark-up-" + System.nanoTime());
    upQueue = SingleChronicleQueueBuilder.binary(upQueuePath).build(); // <1>
    smdWriter = upQueue.createAppender().methodWriter(SidedMarketDataListener.class);  // <2>

    downQueuePath = new File(target, "ComponentsBenchmark-down-" + System.nanoTime());
    downQueue = SingleChronicleQueueBuilder.binary(downQueuePath).build();  // <3>
    MarketDataListener mdWriter = downQueue.createAppender().methodWriter(MarketDataListener.class); // <4>

    SidedMarketDataCombiner combiner = new SidedMarketDataCombiner(mdWriter); //<5>

    reader = upQueue.createTailer().methodReader(combiner); // <6>
    System.out.println("up-q " + upQueuePath);
}

@TearDown
public void tearDown() {
    upQueue.close();
    downQueue.close();
    IOTools.shallowDeleteDirWithFiles(upQueuePath);
    IOTools.shallowDeleteDirWithFiles(downQueuePath);
}

@Benchmark
public void benchmarkComponents() {
    switch (counter++ & 3) {
        case 0:
            smdWriter.onSidedPrice(sidedPrice.init("EURUSD", 123456789000L, Side.Sell, 1.1172, 1e6));
            break;
        case 1:
            smdWriter.onSidedPrice(sidedPrice.init("EURUSD", 123456789100L, Side.Buy, 1.1160, 1e6));
            break;
        case 2:
            smdWriter.onSidedPrice(sidedPrice.init("EURUSD", 123456789000L, Side.Sell, 1.1172, 2e6));
            break;
        case 3:
            smdWriter.onSidedPrice(sidedPrice.init("EURUSD", 123456789100L, Side.Buy, 1.1160, 2e6));
            break;
    }
    assertTrue(reader.readOne()); // <7>
}
----
<1> Create an upstream queue
<2> Create a proxy which writes all methods calls to the upstream queue
<3> Create a downstream queue
<4> Create a proxy for the downstream queue
<5> Create the component which will write all outputs to the downstream queue
<6> Create a reader for the upstream queue which will call the combiner
<7> After writing a message to the queue, read it and call the appropriate method in the component

The first portions sets up and tearsdown the test.  The actual benchmark injects a message which when read and processed will trigger an output message.

.Running the tests in JMH
----
  Percentiles, us/op:
      p(0.0000) =      2.552 us/op
     p(50.0000) =      2.796 us/op
     p(90.0000) =      5.600 us/op
     p(95.0000) =      5.720 us/op
     p(99.0000) =      8.496 us/op # <1>
     p(99.9000) =     15.232 us/op # <1>
     p(99.9900) =     19.977 us/op # <2>
     p(99.9990) =    422.475 us/op
     p(99.9999) =    438.784 us/op
    p(100.0000) =    438.784 us/op
----
<1> Critical latency threashold for many systems.
<2> Can still be important in some systems.

This is running on my development machine which is an E-2650 v2 running Ubuntu.  For better results, I suggest the latest Haswell or Skylake and Centos.  However the exact timing isn't important as the number and type of fields in the mesasge is also is a factor.  What is particularly interesting to be is the 99.9%tile latency (worst 1 in 1000) which is consistently until 20 mciro-seconds in this example.  This demonstrates both high performance and consistently fast latencies.

=== Looking at how JMH is called.

To control how JMH is run I used the following parameters

[source, java]
----
int time = Boolean.getBoolean("longTest") ? 30 : 3;
System.out.println("measurementTime: " + time + " secs");
Options opt = new OptionsBuilder()
        .include(ComponentsBenchmark.class.getSimpleName())
        .warmupIterations(8)
        .forks(1)
        .mode(Mode.SampleTime) // <1>
        .measurementTime(TimeValue.seconds(time))
        .timeUnit(TimeUnit.MICROSECONDS)
        .build();

new Runner(opt).run();
----
<1> `SampleTime` mode to test latencies rather than throughput.

However, I have had trouble profiling and debugging JMH benchmarks so I change the way the test is run depending on how it is started

.Running in Flight Recorder and Debug
[source, java]
----
if (Jvm.isFlightRecorder()) {
    // -verbose:gc -XX:+UnlockCommercialFeatures -XX:+FlightRecorder 
    // -XX:StartFlightRecording=dumponexit=true,filename=myrecording.jfr,settings=profile 
    // -XX:+UnlockDiagnosticVMOptions -XX:+DebugNonSafepoints <2>
    System.out.println("Detected Flight Recorder");
    main.setup();
    long start = System.currentTimeMillis();
    while (start + 60e3 > System.currentTimeMillis()) { // <1>
        for (int i = 0; i < 1000; i++)
            main.benchmarkComponents();
    }
    main.tearDown();

} else if (Jvm.isDebug()) {
    for (int i = 0; i < 10; i++) {
        runAll(main, Setup.class);
        runAll(main, Benchmark.class);
        runAll(main, TearDown.class);
    }
----
<1> Run for 1 minute before shutting down.
<2> Enable profiling between safepoints.

=== In our next part

I would like to look at how we can time just the component running in another thread. In particualr see how long it takes to read, process and write each message with individual timings.


